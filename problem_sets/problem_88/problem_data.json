{
  "index": 88,
  "sector": "factual",
  "difficulty": "normal regularly encountered",
  "problem_statement": "Implement a data warehouse ETL (Extract, Transform, Load) process in Python using the Pandas library to load customer transaction data from CSV files located in '/data/transactions' into a MySQL database named 'customer_database' on a remote server. Ensure that each transaction is assigned a unique identifier and linked to its corresponding customer ID.\nThe transaction CSV files have the following structure:\n- CustomerID (str)\n- TransactionDate (datetime)\n- ProductID (int)\n- Quantity (int)\n- Price (float)\nRequirements:\n- Extract data from all CSV files in '/data/transactions' into a Pandas DataFrame.\n- Transform the data by adding a unique transaction ID and linking each transaction to its corresponding customer ID.\n- Load the transformed data into 'customer_database' table named 'transaction_log'.\n- Create indexes on CustomerID and TransactionDate for efficient querying.\n- Handle potential errors during the ETL process, such as missing or duplicate values.\nUse Python 3.7+ and the Pandas library for data manipulation. Assume that the MySQL database credentials are stored in a separate file named 'db_credentials.json' with the following format:\n```json\n{\n    \"host\": \"remote_server_ip\",\n    \"user\": \"database_username\",\n    \"password\": \"database_password\",\n    \"database\": \"customer_database\"\n}\n```\nProvide a Python script that meets these requirements and includes comments for clarity. Make sure to handle potential edge cases during the ETL process.\n### Hint"
}